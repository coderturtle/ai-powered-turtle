Love that. Hereâ€™s a tight, â€œshow-by-doingâ€ plan that turns your static docs into an **interactive, hands-on program** using **GitHub Copilot** and **Claude Code**. Itâ€™s designed so anyone can clone a repo (or open Codespaces), follow the prompts, and _experience_ hybrid human+agent workâ€”not just read about it.

# 0) What â€œinteractiveâ€ means here

- **A runnable repo** with labs that mirror your experiments (A1, A2, A3).
    
- **Guided prompts** for Copilot & Claude Code embedded right in issues, READMEs, and PR templates.
    
- **CI checks** that score agent-assisted work (tests + â€œevalsâ€).
    
- **Bots-as-coaches**: automated PR comments with next steps, plus â€œgreen-beret hintsâ€ when people get stuck.
    

---

# 1) Repo blueprint (hands-on lab monorepo)

```
hybrid-humans-agents/
â”œâ”€ README.md                          # 5-minute tour + quickstart
â”œâ”€ /labs/
â”‚  â”œâ”€ A1-product-discovery/           # Onboarding journey lab (PM/Design/BA heavy)
â”‚  â”‚   â”œâ”€ README.md                   # Story + acceptance criteria + demo script
â”‚  â”‚   â”œâ”€ /prompts/                   # Prompt recipes (Copilot & Claude)
â”‚  â”‚   â”œâ”€ /brd/                       # BRD templates; â€œagent-draft â†’ human-signâ€
â”‚  â”‚   â””â”€ /ui-prototype/              # Minimal Next.js prototype to iterate
â”‚  â”œâ”€ A2-engineering-cell/            # Refactor fund-selection to micro-frontend
â”‚  â”‚   â”œâ”€ README.md
â”‚  â”‚   â”œâ”€ /app/                       # Starter code w/ failing tests & TODOs
â”‚  â”‚   â”œâ”€ /tests/                     # Unit/contract/property tests
â”‚  â”‚   â””â”€ /evals/                     # Simple eval harness (e.g., pytest scripts)
â”‚  â””â”€ A3-advisor-service-desk/        # Advisor support workflow (Writer/MS 365 Copilot)
â”‚      â”œâ”€ README.md
â”‚      â”œâ”€ /playbooks/                 # Email templates, policy clauses, disclaimers
â”‚      â””â”€ /workflow/                  # Minimal service app stub (forms + summaries)
â”œâ”€ /ops/
â”‚  â”œâ”€ golden-pipeline.md              # â€œPolicy lives in the pipelineâ€ checklist
â”‚  â””â”€ evidence-pack.md                # What to capture for audit-by-default
â”œâ”€ /.github/
â”‚  â”œâ”€ ISSUE_TEMPLATE/
â”‚  â”‚   â”œâ”€ 01_lab_task.yml             # Pre-filled tasks with agent prompts
â”‚  â”‚   â””â”€ 02_retro.yml                # What data and reflections to capture
â”‚  â”œâ”€ PULL_REQUEST_TEMPLATE.md        # â€œWhat did the agent do vs you?â€ + checkboxes
â”‚  â””â”€ workflows/
â”‚      â”œâ”€ ci.yml                      # build/test + evals + artifact report
â”‚      â””â”€ pr-comment.yml              # posts coach-style feedback on PRs
â””â”€ /dev/
   â”œâ”€ devcontainer.json               # Codespaces/Dev Container w/ Copilot enabled
   â””â”€ editor-setup.md                 # How to enable Claude Code + Copilot locally
```

---

# 2) Codespaces & local dev: zero-friction start

- **devcontainer.json** pre-installs Node/Python + test tools, enables GitHub Copilot, and includes a â€œStart Hereâ€ postCreateCommand that:
    
    - opens `/labs/A1-product-discovery/README.md`,
        
    - runs `npm install` for prototypes,
        
    - prints â€œTry these Copilot/Claude promptsâ€ next steps in the terminal.
        

---

# 3) â€œGuided promptsâ€ woven into the work

Each lab has **copy-pasteable prompt cards** that participants use in Copilot Chat or Claude Code. Examples:

### Copilot (PM/BA/Design)

- â€œDraft a BRD from these user stories and acceptance criteria (below). Add explicit out-of-scope, risks, and open questions.â€
    
- â€œGenerate a testable epic â†’ story â†’ task tree for the onboarding journey targeting . Include a definition of done per task.â€
    

### Claude Code (Engineers/Architects)

- â€œGiven `app/` and `tests/`, refactor `FundSelector` into a micro-frontend while preserving all contract tests. Propose a rollout plan (behind a flag) and create migration steps.â€
    
- â€œWrite property tests for `PortfolioRebalancer` covering edge cases for fee thresholds and currency rounding.â€
    

### Mixed (Advisor Support)

- â€œFrom `/playbooks/suitability-clauses.md`, draft a client-ready email comparing Fund A vs Fund B with required disclaimers; keep reading age 9â€“10, add a â€˜check with your advisorâ€™ CTA.â€
    

---

# 4) Issue & PR templates that teach by doing

**Issue template** (excerpt):

```yaml
name: A2 â€“ Refactor task
body:
  - type: markdown
    attributes:
      value: |
        **Goal**: Extract FundSelector into `mf-fund-selector` MFE.
        **Try this in Copilot Chat**: â€œOutline a safe MFE extraction plan with steps and guardrails.â€
  - type: checkboxes
    attributes:
      label: Did you try these?
      options:
        - label: Copilot: scaffold tests first
        - label: Claude Code: generate refactor plan & migration script
        - label: Human review of API boundaries completed
  - type: textarea
    attributes:
      label: What the agent proposed vs what you accepted (and why)
```

**PR template** (excerpt):

```md
### What did the agent propose vs. what shipped?
- Agent diffs attached? â˜
- Human changes & rationale:

### Evidence by default
- [ ] Contract & property tests added
- [ ] Eval report attached (artifact link)
- [ ] Policy checklist passed (PII, logging)
```

---

# 5) CI that â€œscoresâ€ the work (gentle, useful)

**.github/workflows/ci.yml** runs:

- `npm test` / `pytest` (unit + contract + property tests)
    
- `/labs/**/evals/` scripts (simple evals that produce a JSON or HTML report)
    
- uploads an **artifact** (`/artifacts/eval-report.html`)
    
- **comments** on the PR with a friendly rubric (pass/fail, â€œtry this nextâ€)
    

Example PR comment:

> âœ… Tests: 42/42 pass.  
> ğŸ§ª Evals: 3/4 pass (edge case: non-GBP rounding failed).  
> ğŸ” Tip: Ask Copilot to â€œgenerate property tests for non-GBP fee rounding using these invariantsâ€¦â€

---

# 6) The three interactive labs that map to your experiments

### Lab A1 â€” **AI-Augmented Product Discovery**

- Start with a minimal Next.js journey (two screens).
    
- Use **MS 365 Copilot** to draft the BRD; **Writer** for client-facing copy.
    
- Gate to done: prototype + BRD + â€œagent vs humanâ€ summary in PR.
    

### Lab A2 â€” **Agentic Engineering Cell**

- Start with failing tests & TODOs in `app/`.
    
- Use **Claude Code** for refactor plans & scaffolding; **Copilot** for tests & docs.
    
- Gate: micro-frontend behind a flag, full tests, evals pass.
    

### Lab A3 â€” **AI-Enhanced Advisor Service Desk**

- Starter workflow (form + template rendering).
    
- Use **Writer** to generate compliant advisor comms; **MS 365 Copilot** for Excel what-ifs.
    
- Gate: live-ready artifact, disclaimers inserted, evidence pack updated.
    

---

# 7) â€œCoachâ€ automation: lightweight PR helper

Add a simple Action (`pr-comment.yml`) that posts coach tips keyed to test/eval results. It doesnâ€™t need external APIsâ€”just parses test output and prints tailored guidance (e.g., â€œconsider property-based tests,â€ â€œsplit business rules from UIâ€).

---

# 8) Leaderboard & telemetry (privacy-safe)

- A tiny `/scripts/log_usage.sh` that contributors run to append anonymised metrics (time spent, prompts used) to `/metrics/usage.csv`.
    
- A `make dashboard` command renders a simple HTML leaderboard (commits, eval passes, time-to-first-PR).
    

---

# 9) â€œGreen-Beret hintsâ€

Create `/hints/` with short, surgical exemplars:

- â€œSafe rollout with feature flagsâ€
    
- â€œDesign a contract test firstâ€
    
- â€œProperty testing invariants: fees & roundingâ€  
    Each hint page ends with a **copyable Copilot & Claude prompt**.
    

---

# 10) Live â€œdojoâ€ format (1 hour)

1. **5 min**: Open Codespaces â†’ run quickstart.
    
2. **10 min**: Copilot â€œstory slicingâ€ & BRD draft (A1).
    
3. **25 min**: Claude Code refactor + tests (A2).
    
4. **10 min**: Run CI â†’ review evals â†’ PR comment coaching.
    
5. **10 min**: Retro: â€œwhat the agent did vs what we acceptedâ€.
    

---

# 11) Role-specific on-ramps (who benefits and how to start)

- **PM / BA**: Start in A1. Use MS Copilot to draft BRDs; iterate with Writer for client-safe language. Aim: _cut BRD time by 40%_.
    
- **Engineers**: Start in A2. Use Claude Code for plans/scaffolds; Copilot for tests/docs. Aim: _+20% throughput without quality loss_.
    
- **Architects**: Review A2 designs; add `/ops/golden-pipeline.md`. Aim: _interactive docs + exemplar patterns_.
    
- **QA (Scenario Engineers)**: Own `/labs/**/evals/` and property tests. Aim: _evals as first-class citizens_.
    
- **Advisor Support / Marketing**: A3 flow. Writer for compliant comms, Copilot for Excel what-ifs. Aim: _+10% FCR, â€“15% AHT_.
    
- **Compliance / Risk**: Add checklists to PR template; verify `/ops/evidence-pack.md`. Aim: _evidence-by-default_.
    

---

# 12) What I can generate next (fast)

- A **starter repo** with all the above files scaffolded (README, issue/PR templates, Actions, lab stubs, eval harness, devcontainer).
    
- Optional: a **one-page facilitator guide** for running the 60-min dojo.
    
- Optional: a **progress badge** system (shields) that lights up when a team passes A1/A2/A3.
    

If you want, Iâ€™ll spin up the repo skeleton (with realistic sample code and tests) so you can start running sessions this week.